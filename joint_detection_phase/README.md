# SHS_NET joint detection phase
The joint detection phase aims to identify the joint coordinates in the image by weakly supervised learning using heat-mapped images based on U-Net. An overview of this phase follows.

![joint_detection2](https://user-images.githubusercontent.com/80377824/171571670-1247f528-e6bf-451d-98e1-0bbd45195f6c.png)


# Code Architecture
<pre>
.　　
├── data_set                    # hand radiographs for training.   
│   ├──images                   # Directory to store hand radiographs generated by orientation model. Please copy the images generated in the output directory of orientation_phase to this directory.
│   ├──masks                    # Directory to store heatmaps generated by heatmap_generator.ipynb
│   │  ├──0                     # Directory where the heatmap image of joint number 0 (IP joint in this model) is stored
│   │  ├──1                     # Directory where the heatmap image of joint number 1 (PIP2 joint in this model) is stored
│   │    ...
│   ├──test                     # Directory to store hand radiographs for testing and each joint image that was cropped 
│   └──coord_list.csv           # Correct label list of 15 joint coordinates for each hand radiograph. This list is used in heatmap_generator.ipynb to generate a heatmap from the joint coordinates
├── hand_test                   # hand radiographs for testing (align the orientation and/or split)                    
├── orientation_phase       
│   └── orientation_pred_log               
│       └── models              # Directory to store config, log and weight parameter files  
├── output                      # Directory to store output images from the model  
├── Orientation_detector.ipynb  # main code of orientation phase  
├── README.md                   # README file  
├── adabound.py                 # code for adabound, a type of optimizer  
├── archs.py                    # code for architecuture of EfficientNet b0  
├── dataset.py                  # code for making data-loader from images in hand_all_rotation dir and image_list_hand_ver3.csv  
├── image_list_hand_ver3.csv    # csv file including image id and true label  
├── losses.py                   # code for loss function  
├── train_val.py                # code for training and validation  
└── utils.py                    # common useful modules (to make scheduler, optimizer, label maker for training and validation etc.)  
</pre> 

This repository contains dummy images obtained from [RSNA-Pediatric-Bone-Age-Challenge-2017](https://www.rsna.org/education/ai-resources-and-training/ai-image-challenge/RSNA-Pediatric-Bone-Age-Challenge-2017)   
Halabi SS, Prevedello LM, Kalpathy-Cramer J, et al. The RSNA Pediatric Bone Age Machine Learning Challenge. Radiology 2018; 290(2):498-503.

code of adabound can be found [here](https://github.com/Luolc/AdaBound)
